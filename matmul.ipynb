{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ninetoothed\n",
    "import torch\n",
    "import triton\n",
    "from ninetoothed import Symbol, Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matmul(lhs, rhs):\n",
    "    BLOCK_SIZE_M = Symbol(\"BLOCK_SIZE_M\", meta=True)\n",
    "    BLOCK_SIZE_N = Symbol(\"BLOCK_SIZE_N\", meta=True)\n",
    "    BLOCK_SIZE_K = Symbol(\"BLOCK_SIZE_K\", meta=True)\n",
    "\n",
    "    output_tiled = Tensor(2).tile((BLOCK_SIZE_M, BLOCK_SIZE_N))\n",
    "\n",
    "    lhs_tiled = (\n",
    "        Tensor(2)\n",
    "        .tile((BLOCK_SIZE_M, BLOCK_SIZE_K))\n",
    "        .tile((1, -1))\n",
    "        .expand((-1, output_tiled.shape[1]))\n",
    "    )\n",
    "    rhs_tiled = (\n",
    "        Tensor(2)\n",
    "        .tile((BLOCK_SIZE_K, BLOCK_SIZE_N))\n",
    "        .tile((-1, 1))\n",
    "        .expand((output_tiled.shape[0], -1))\n",
    "    )\n",
    "\n",
    "    @ninetoothed.jit\n",
    "    def matmul_kernel(lhs: lhs_tiled, rhs: rhs_tiled, output: output_tiled):\n",
    "        accumulator = ninetoothed.language.zeros(\n",
    "            output.shape, dtype=ninetoothed.language.float32\n",
    "        )\n",
    "        for k in range(lhs.shape[1]):\n",
    "            accumulator = ninetoothed.language.dot(lhs[0, k], rhs[k, 0], accumulator)\n",
    "        output = accumulator.to(ninetoothed.language.float16)\n",
    "\n",
    "    output = torch.empty(\n",
    "        (lhs.shape[0], rhs.shape[1]), device=lhs.device, dtype=torch.float16\n",
    "    )\n",
    "\n",
    "    matmul_kernel(lhs, rhs, output)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "shape = (512, 512)\n",
    "lhs = torch.randn(shape, device=\"cuda\", dtype=torch.float16)\n",
    "rhs = torch.randn(shape, device=\"cuda\", dtype=torch.float16)\n",
    "torch_output = torch.matmul(lhs, rhs)\n",
    "ninetoothed_output = matmul(lhs, rhs)\n",
    "print(torch_output)\n",
    "print(ninetoothed_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@triton.testing.perf_report(\n",
    "    triton.testing.Benchmark(\n",
    "        x_names=[\"M\", \"N\", \"K\"],\n",
    "        x_vals=[128 * i for i in range(2, 33)],\n",
    "        line_arg=\"provider\",\n",
    "        line_vals=[\"ninetoothed\", \"cublas\"],\n",
    "        line_names=[\"NineToothed\", \"cuBLAS\"],\n",
    "        styles=[(\"blue\", \"-\"), (\"green\", \"-\")],\n",
    "        ylabel=\"TFLOPS\",\n",
    "        plot_name=\"matrix-multiplication-performance\",\n",
    "        args={},\n",
    "    )\n",
    ")\n",
    "def benchmark(M, N, K, provider):\n",
    "    a = torch.randn((M, K), device=\"cuda\", dtype=torch.float16)\n",
    "    b = torch.randn((K, N), device=\"cuda\", dtype=torch.float16)\n",
    "    quantiles = [0.5, 0.2, 0.8]\n",
    "    if provider == \"cublas\":\n",
    "        ms, min_ms, max_ms = triton.testing.do_bench(\n",
    "            lambda: torch.matmul(a, b), quantiles=quantiles\n",
    "        )\n",
    "    if provider == \"ninetoothed\":\n",
    "        ms, min_ms, max_ms = triton.testing.do_bench(\n",
    "            lambda: matmul(a, b), quantiles=quantiles\n",
    "        )\n",
    "\n",
    "    def perf(ms):\n",
    "        return 2 * M * N * K * 1e-12 / (ms * 1e-3)\n",
    "\n",
    "    return perf(ms), perf(max_ms), perf(min_ms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark.run(show_plots=True, print_data=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
